# 【视频文稿】11.卷积神经网络：图像识别实战

上节课我们已经了解到卷积操作是怎么一回事，那接下来我们就看看如何把卷积运算融入到我们的神经网络之中。

这是一张8×8的灰度图，用一个3×3的卷积和对它进行卷积输出一个6×6的结果，我们把这个做卷积运算的一层称之为卷积层，卷完以后我们就可以把结果拆成一个数组送入到后面的全连接层神经网络之中，但是你肯定会有一个疑问，这个卷积盒中的各个值是多少？是这样垂直边缘检测的和还是这样水平边缘检测的和还是其他的河。好问题，实际上我们不必管它随机初始化这些值就好，卷积核的值也是通过训练学习而来的。

![image](https://cdn.jsdelivr.net/gh/Achuan-2/PicBed@pic/assets/image-20220815171430-fp04gus.png)​

换句话说通过训练找到合适的卷积核去提取不同的特征，那我们卷积盒中的参数又是怎么学习来的？还是像全连接层的普通神经元那样通过反向传播和梯度下降吗？

是的，从某种角度来看，卷积层除了对数据的提取方式不同以外，其他部分和一个全连接层也没有什么区别，按照最简的讲解原则，假设我们的原始图像的大小只有4×4，四用一个3×3的卷积核去卷，它得到一个2×2的矩阵，卷完以后我们再送入一层全连接层中，简单起见，假设只有两个神经元再经过输出层，mnist的数据集是10分类的问题，所以输出层有10个神经元最后得到预测结果，这是目前前向传播的过程，那么反向传播的过程就是这样，后面两层和以前一样很简单，先求代价函数，然后利用链式法则把误差代价传播到这两层的各个权值和偏置参数上，那到这里，接下来该怎样呢？

我们的误差代价如何传播到这个卷积层，好像不能按照普通神经元的方式继续下去了。实际上我们完全可以从某种角度把卷积层发生的事情类比到我们之前所说的普通神经元，我们知道卷积的过程就是卷积和依次和这些小图对应的元素相乘在相加得到一个值，比如卷积的第一步是卷积和和左上角的第一个3×3的小图，对的元素相乘之后再相加，你看这像不像一个普通神经元的工作模式？

![image](https://cdn.jsdelivr.net/gh/Achuan-2/PicBed@pic/assets/image-20220815171627-dzvieuc.png)​

这个3×3的小图的每个像素点就是输入数据，卷积合上的值可以看作是对应输入数据的全值、参数w那么对应元素相乘之后再相加，所以这不就是一个9个输入和一个输出的普通神经元的线性运算部分吗？同样第二个3×3的小图通过同样的方式得到第二个结果，这又可以用一个普通的神经元来表示，第三个小图也对应一个普通的神经元，第四个小图也对应一个普通的神经元，当然神经元的线性函数一般还需要加一个偏执向b所以我们实际上会让卷积的结果再加上一个b这样就真的和之前的普通神经元的线性运算部分一样，当然如果想要和一个普通神经元彻底一样，那我们还需要在线性运算之后也通过激活函数进行非线性运算，这才是卷基层的最终输出，这样我们就把1个卷积层拆成了4个普通的神经元。

![image](https://cdn.jsdelivr.net/gh/Achuan-2/PicBed@pic/assets/image-20220815171648-qiosxkd.png)​​

那既然如此，那我们就可以像之前在普通神经元中那样很轻松的继续把误差代价反向传播下去。当然这4个神经元和普通的神经元相比还是有几个细节不太一样。首先这4个神经元的输出是根据卷积的过程排列而成的二维结构，而不是这样的平铺，当然在送入后面的全连接层的时候，我们需要手动把它平铺开，然后这4个神经元的输入并不相同，实际上是同1个图片的不同区域，最后也是最重要的一点，这4个神经元的权值参数并不是独立的，因为我们把卷积合的值看作是权值参数，而这4个神经元的权值参数都来自于同1个卷积盒，所以实际上他们的权值参数是一样的，我们只是把1个东西强行拆开频谱，出成了4个，也就是说这4个神经元复用了同1套权重参数，这就是所谓的**参数共享**，这是卷积层的优势之一。

相比之下如果我们使用全连阶层这个4×4的图像数据就需要变成16维的向量，那么就会有16个权重参数和一个偏执参数，一共17个参数，那要像这个卷积层一样得到4个输出，就需要4个审定员，这样的1个全连接层就需要17×4=68个参数，而卷积层因为因为共享的参数只有3×3=9个参数，再加1个偏置，参数b是10个，这是4×4的图像，实际上真实的图片往往比较大，比如8×8的图片为了得到4个输出，这样的一个全年阶层需要260个参数，但如果还是使用3×3的卷积和的卷，基层那么还是只有10个参数，再比如我们的MS的数据集是28×28的图片需要3140个参数，而如果是我们拍摄的高清大图，那这个参数将变得很大很大，而网络参数越多也就意味着训练将变得困难和缓慢，但是用3×3卷积和的卷积层还是只需要10个参数，但为什么共享参数它就行得通，这就回到了一开始的那个问题，卷积到底是在提取什么呢？​

我们已经说过利用卷积可以提取比如轮廓纹理这样的特征，假如通过训练之后这个卷积合变成了一个提取垂直边缘的卷积和那么一个图像不论是在左上角还是在右下角，还是在其他什么地方提取垂直边缘的方式都是一样的，所以我们的垂直参数可以共享，所以说卷积和的参数并不是我们事先设置好的，而是像普通神经元的权重参数一样通过训练学习而来，但是一个卷积核训练的结果是提取图像的一种特征，这还不够，我们需要提取图像更多的特征方法也很简单，那就是再搞一个卷积核提取第二种特征，再搞一个提取第三种。

![image](https://cdn.jsdelivr.net/gh/Achuan-2/PicBed@pic/assets/image-20220815171848-oa2461l.png)​

那实际上你想要提取多少特征就搞多少个卷积核就可以，而这三个卷积核卷出来的三个结果就是一个三维的张量，我们可以把这个三维张量中的数据铺开成为一个一维的向量，然后在后面构造全连接层神经网络，把这个铺平的向量作为数据输入其中，然后该干嘛干，但在送入全连接层之前，那我们还能不能继续去卷这个6×6×3的数据？

当然可以，比如在卷积神经网络发展的早期深度学习领域，巨头人物Lecun在1999年就提出了一种经典的卷卷积神经网络结构，net5Nile的5网络中就卷了两次之后再输入全年阶层，但我们怎么去卷这个6×6×3的三维数据？实际上卷积运算不仅可以在二维上进行，同样也可以在三维数据上进行。我们在二维数据上使用的是一个二维的卷积和那自然，在三维数据上我们使用三维的卷积和我们使用一个3×3×3的三枚卷积核去，卷上一个卷积层输出的6×6×3的数据，三维卷积的方式和二维几乎一模一样，二维卷积是把卷积合照在二维数据上找到对应位置相乘，然后加起来的三维卷积同样是找到数据和卷积立方块对影的位置的元素相乘，然后加起来得到一个结果，过程一模一样，只不过从二维变成了三维，当然最后还要让卷积的结果加上偏执，在在经过计划函数做非线性运算得到最后的输出，这样一趟卷下来就变成了4×4的输出。​

当然第二层卷积层我们也可以使用多个三维的卷积，合比如我们搞4个三维的卷积和这样输出的结果就变成了4×4×4，这又是一个三维的张量数据，被卷积和卷积的数据的第三个维度值，也就是所谓的通道数为啥叫通道数？我们来看第一个卷积层，如果我们的图像是彩色的，那这个名字就相当合理的。我们说灰度图像的数据是二维的，而彩色图片、则有、RGB三个通道，所以我们的输入是一个三通道的图像，那么自然就是一个长乘以宽乘以3的三维数据。

![image](https://cdn.jsdelivr.net/gh/Achuan-2/PicBed@pic/assets/image-20220815171938-s1gp35r.png)​

你看第三个维度的大小三就表示有三个通道，所以我们把数据的第三个维度的值也就称之为通道的数量，要对这样的数据进行卷积，那卷积核也必须是三维的，而且第三个维度的值也必须和数据的通道数一样，不然罩不住。

那么思考一下，如果我们还想把第二个卷积层的输出结果继续卷那需要什么样的卷积合呢没错，为了让卷积核能够罩得住数据卷积合的第三个维度值需要和数据的通道数一样，我们可以使用3×3×4的卷积和当然3×3可以换成其他的大小，但是为了能够罩住输入数据，这个4是不能换的，同样如果是用5个3×3×4的卷积和那么这一卷积层的最后输出就是一个2×2×5的张量数据。好的，我们已经说完了如何把卷积操作应用到神经网络结构中变成卷积神经网络，但我们刚才提到了这个经典的历代的卷积神经网络中，除了我们熟悉的这两个卷积层和后面的全连接层以外，还还多出了两个立方块，这是何物？

这两个立方块就是所谓的池化层，先看是什么，再说为什么。简单起见，我们还是以单个卷积核为数据为例，比如经过第一层卷积层8×8的数据，被3×3的卷积和卷成了6×6的输出，这个输出接下来就进入池化层进行池化操作，是这样的。​​

我们从这个数据的左上角开始框出一个比如2×2的区域，当然不一定非得是2×2，然后求出这2×2个数据的平均值得到一个结果，然后像拳击操作那样向后移动一步，再求出这个2×2数据的平均值得到第二个结果，然后一直顶到最右边，再向下移动一个像素换到下一行重，从新从左到右的得到这些2×2数据的平均值，这个操作就是池化，这就是池化得到的结果，当然我们不仅可以采用平均值的方式，还还有一种常见的方法是取最大值，这种取最大值的方式也叫MaxPooling最大池化，前面取平均值的方式也叫阿瑞智普里平均池化，而对于多通道的三枚数据，其实简单的不行，比如用最大池化，那么我们就在每个通道上都这么操作就好了，结果还是和卷积层输出的通道数一样的一个立方块，不过经过池化之后便细小了而已。

好的，说完是什么？那说为什么？虽然人们关于池化层有一些看似很有道理的分析，比如最大池化层让最大的值被筛选了出来，能很好的提取主要特征，但是我个人的看法，这只是一个工程上的规则，原因就是人们发现加入池化层之后往往效果不错，所以虽然在很多经典的卷积神经网络中，往往都会在卷基层之后加上池化层，但这并不是必须的，还有一点实话操作，因为是固定的套路，所以在反向传播中，他并没有任何需要学习的参数。

## 编程实验

### LeNet-5卷积神经网络模型：识别acc98.4%

* 模型

  * ![image](https://cdn.jsdelivr.net/gh/Achuan-2/PicBed@pic/assets/image-20220813142257-uzxb3f3.png)​
  * 6核(5,5)卷积层+平均池化层(2,2)+6核(5,5)卷积层+平均池化层(2,2)+120个神经元全连接层+84个神经元全连接层+10个神经元softmax输出层
  * 除了最后一层输出层激活函数选择softmax,其他层激活函数都选择relu
  * optimizer选择SGD。学习率0.05，损失函数选择categorical_crossentropy
  * 训练epochs=3000, batch_size=4096
  * 使用60000个手写图片进行训练
* 测试结果:使用10000个手写图片进行测试

  * 总的识别率:98.4%
* 代码

  ```python
  import numpy as np
  import matplotlib.pyplot as plt
  from keras.models import Sequential
  from keras.layers import Dense
  from keras.optimizers import SGD
  from keras.models import load_model
  from keras.datasets import mnist
  from tensorflow.keras.utils import to_categorical
  from keras.layers import Conv2D
  from keras.layers import AveragePooling2D
  from keras.layers import Flatten

  (X_train, Y_train), (X_test, Y_test) = mnist.load_data()


  X_train = X_train.reshape(X_train.shape[0], 28,28,1)/255.0
  X_test = X_test.reshape(X_test.shape[0], 28,28,1)/255.0

  Y_train = to_categorical(Y_train, 10)
  Y_test = to_categorical(Y_test, 10)


  # 创建模型
  model = Sequential()
  """ 
  strides = (1,1)：每次滑动步长为1
  padding ='valid'不加填充 / 'same' 填充前后不变
  """
  model.add(Conv2D(filters=6, kernel_size=(5,5), strides=(1,1),padding='valid',activation='relu', input_shape=(28,28,1)))
  model.add(AveragePooling2D(pool_size=(2,2))) # 平均池化层
  model.add(Conv2D(filters=16, kernel_size=(5,5), strides=(1,1),padding='valid',activation='relu'))
  model.add(AveragePooling2D(pool_size=(2,2)))
  model.add(Flatten())
  model.add(Dense(units=120, activation='relu'))
  model.add(Dense(units=84, activation='relu'))
  model.add(Dense(units=10, activation='softmax'))  # 输出层用softmax函数,做多分类

  # 送入训练
  model.compile(loss='categorical_crossentropy', optimizer=SGD(
      learning_rate=0.05), metrics=['accuracy'])  # 多分类问题使用交叉熵做代价函数
  model.fit(X_train, Y_train, epochs=3000, batch_size=4096, verbose=1)


  # 训练完毕，查看loss和accuracy
  loss, accuracy = model.evaluate(X_test, Y_test)
  print(f"{loss=}")
  print(f"{accuracy=}")
  # 保存模型
  model.save('./model/11_LeNet-2.h5')
  ```

### 自行搭建的卷积神经网络模型：识别acc99.21%

* 模型搭建

  * ![image](https://cdn.jsdelivr.net/gh/Achuan-2/PicBed@pic/assets/image-20220813142142-evorcjs.png)​
  * 32核(3,3)卷积层+最大池化层(2,2)+64核(3,3)卷积层+64核(3,3)卷积层+64个神经元全连接层+10个神经元softmax输出层
  * 除了最后一层输出层激活函数选择softmax,其他层激活函数都选择relu
  * optimizer选择adam,损失函数改用sparse_categorical_crossentropy
  * 训练epochs=200, batch_size=32
  * 使用60000个手写图片进行训练
* 测试结果:使用10000个手写图片进行测试

  * 总的识别率:99.21%,79个手写数字(总共10000个测试图片)未成功识别
  * 各手写数字识别率

    * 0: 99.49%
    * 1: 99.21%
    * 2: 99.22%
    * 3: 99.60%
    * 4: 99.29%
    * 5: 98.88%
    * 6: 98.85%
    * 7: 99.32%
    * 8: 99.49%
    * 9: 98.71%
  * 识别率最高的数字是：3,识别率为：99.60%
  * 识别率最低的数字是：9,识别率为：98.71%
* 代码

  ```python
  import numpy as np
  import matplotlib.pyplot as plt
  from keras.models import Sequential
  from keras.layers import Dense
  from keras.models import load_model
  from keras.datasets import mnist
  from keras.layers import Conv2D
  from keras.layers import AveragePooling2D,MaxPooling2D
  from keras.layers import Flatten

  (X_train, Y_train), (X_test, Y_test) = mnist.load_data()


  X_train = X_train.reshape(X_train.shape[0], 28,28,1)/255.0
  X_test = X_test.reshape(X_test.shape[0], 28,28,1)/255.0

  # Y_train = to_categorical(Y_train, 10)
  # Y_test = to_categorical(Y_test, 10)


  # 创建模型
  model = Sequential()
  model.add(Conv2D(filters=32, kernel_size=(3, 3), strides=(
      1, 1), padding='valid', activation='relu', input_shape=(28, 28, 1)))
  model.add(MaxPooling2D((2, 2)))
  model.add(Conv2D(filters=64, kernel_size=(3, 3), strides=(
      1, 1), padding='valid', activation='relu'))
  model.add(Conv2D(filters=64, kernel_size=(3, 3), strides=(
      1, 1), padding='valid', activation='relu'))
  model.add(Flatten())
  model.add(Dense(64, activation='relu'))
  model.add(Dense(10, activation='softmax'))



  model.compile(optimizer='adam',
                loss='sparse_categorical_crossentropy',
                metrics=['accuracy'])
  model.fit(X_train, Y_train, epochs=200, batch_size=32, verbose=1)


  # 训练完毕，查看loss和accuracy
  loss, accuracy = model.evaluate(X_test, Y_test)
  print(f"{loss=}")
  print(f"{accuracy=}")
  # 保存模型
  model.save('./model/11_CNN.h5')
  ```
