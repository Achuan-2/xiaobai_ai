# 【视频文稿】10.卷积神经网络：打破图像识别的瓶颈

## 图片识别

在机器学习神经网络领域，对于不想过多了解底层原理的初学者而言，其实有一个应用层面一般意义上的经典“hello word”，那就是手写体识别。因为其实场景和问题都很简单明确，更有经典的数据集mnist成为了众多入门者必备的实践项目。mnist的数据集的图片采用的是28×28的灰度图，灰度图显示图像的原理是这样的，一行有28个像素点一共有28行，每个像素用一个自己的无符号数表示它的等级，如果是0那就是最暗纯黑色，如果是一个字集的最大值255，那么就是最亮纯白色，如果是中间的值，那就是介于两者之间的灰色，我们通过让不同像素点的灰度值不同而达到显示的效果。

比如这是数字5，这是数字3，但无趣的是如果用键盘输入这些数字图像，那么判断起来没有任何的难度，因为精确的计算机在显示同一个字符的时候，每一次每个像素点的灰度值都是一样的，但人毕竟不同于精准，但呆板的计算机，比如我们拿一支手写笔在这个28×28的屏幕上手写，数字5第一次可能写成这样，下一次可能因为手抖写成这样，每一次都不太一样，这时候也就没有什么确定的规则去根据这些像素的灰度值判断是什么数字了。​

换句话说，这不再是一个适用于计算机机械逻辑做判断的问题，我们需要用有一定容错能力的系统来做这件事情，很明显神经网络是一个很好的选择，我们已经知道如何搭建一个神经网络，那现在唯一的问题是如何把这些图片送其中。

神经网络的输入是一个多维的向量或者说一个数组，而图片是一个方形的像素灰度值的集合。没错，我们把这些像素从头到尾一行一行的依次拉出来就好，mnist的数据集每张图片的尺寸是28×28，所以这将拿出784个像素，每个像素都是一个灰度值，所以这将形成一个784维的向量，或者说一个有784个元素的数组，我们只需要把mnist的数据集中了，每个手写体的图片都变成这样的784个元素的数组，依次送进一个神经网络进行训练就好，最开始人们利用深度全连接神经网络取得了不错的效果，但并不十分的好。

## 训练集和测试集 vs 过拟合和欠拟合

在机器学习的工作流程中，我们在训练时使用的数据集称之为训练集，当然我们希望在训练集上的准确率很高，这意味着模型拟合的效果很棒，但我们会在训练之后，在训练集数据之外，拿一些新的数据进行预测，看看这些新的数据在模型上的准确率如何，这些用来测试的样本数据称之为测试集，我们希望在测试集上的准确率也很高，实际上我们在考量一个模型好坏的时候，更倾向于他在测试集上的表现。因为在测试集上的高准确率意味着模型在遇到训练中没有遇到过的新问题时，也能很准确的进行预测，换句话说这个模型有足够的泛化能力，而模型在训练集和测试集上的不同表现，也就导致了机器学习中三种常见的现象。​

第一，如果在训练集上的准确率都很低，那这个模型多半是废了，这种现象称之为欠拟合，可能是因为模型太过简单，比如我们之前说过用一个神经元试图拟合弯曲分布的数据，这是行不通的。

第二，如果在训练集上的准确率很高，而且在测试集上的支持率也很高，并且相差不大，那说明这个模型通过训练拥有了很好的泛化能力去解决新的问题。

第三，如果在训练级上的准确率很高，但是在测试级上的准确率却出现了明显的下降，那说明这个模型的泛化能力不行，也就很难推而广之，这种现象我们称之为过拟合。

导致过拟合的原因有很多，比如我们用一个过分复杂的模型去拟合一些实则比较简单的问题，我们以豆豆的数据集举个例子，这是训练集，这是测试题，我们在训练集上反复的训练，最后得到这样的结果，这时候在训练集上的准确率已经相当高了，几乎100%，但遗憾的是当我们把这个模型应用到测试集上，准确率就出现了明显的下降，直观上我们能看出来，正是因为在训练集上追求过分精确的拟合，导致模型在新的问题中表现反倒没有那么的好。​

如果类比到人类的学习过程的话，这种学习效果很像在习题中死记硬背，而不是理解问题，或者说钻牛角尖想多了，而测试题就像考试这就出现了平时习题没少写，结果考试成绩并不理想情况，因为模型不够泛化，或者说没有很好的把握事物的主要矛盾，解决神经网络中过拟合的现象也有很多方式，比如调整神经网络的结构，L2正则化，节点失活、正则化等等，我们的课程就不展开讲解这些比较繁琐的问题了，有兴趣的同学可以自行查阅相关的文档进行学习。

第四种情况训练级的准确率很低，但测试级的准确率却很高，从概率上来说，这种见鬼的情况几乎不存在。​

## Lecun表格

mnist的数据集有6万个训练级样本和1万个测试级样本，而人们发现在用全连接神经网络做m类似的数据及识别以及其他图像识别的时候，尽管我们已经把网络堆积的越来越深，神经元的数量也越来越多，也用尽了各种防止过敏和的方法，但网络的办法能力仍然越来越难有所突破，深度学习巨头人物之一的Lecun制作了一个[完整的表格](http://yann.lecun.com/exdb/mnist/)，罗列了机器学习各个领域在Mnist的数据集上的工作成果，从线性分类器、KNN、Boosted Stumps、SVM直到神经网络和卷积神经网络。判断的标准就就是在测试集上的错误率，就像我们说的模型，只有在测试集上的准确率上去了，才是有足够泛化能力的好模型。

目前对于纯粹的深度神经网络，最好的效果是2010年的一个6层网络（错误率0.35%），但是网络规模已经达到了每一层神经元的数量，分别是2500、2000 1500、1000、500这样的巨大规模，作者也毫不避讳的说道，他们就是在用暴力他们有能够加速训练的显卡。

![image](https://cdn.jsdelivr.net/gh/Achuan-2/PicBed@pic/assets/image-20220815170445-whotit4.png)​

这个网络的规模和结果，或许就是人们在mnist的问题上，用纯粹的全连接深度神经网络的极限了。如果继续练死劲，意义然不大，数量的堆积已经很难带来质量的提升。此时神经网络的能力用时下流行的词汇来说，就是内卷。内卷现象，在任何时候任何地方都是糟糕的。打败神经网络能力陷入类卷的方式是另外一种卷法，卷肌我们来看卷肌神经网络在m4的数据集中的成果，即使是早在1998年就被提出的经典的卷积神经网络，LetNet-5也让测试集的准确率达到了99.2%，而2012年更是把准确率提高到了99.77%，所以为什么卷积神经网络会有这么好的效果？

![image](https://cdn.jsdelivr.net/gh/Achuan-2/PicBed@pic/assets/image-20220815170527-7seeuql.png)​

## 卷积怎么工作

首先你要知道卷积选择怎么工作的，请问这是什么？请问这又是什么？对，你不知道也没有人知道。这实际上是把一个图像的像素变成数组之后的样子，而当我们还原之后对没有人不知道这是一个茶杯，这是一个口罩，所以作为人我们在识别一个图片内容的时候，如果看到的是一个个像素连接起来的数组，那是很难作出判断的。当然也不是完全不可能比如死记硬背的记住这些数据的样子，但这又是什么？不错，这还是茶杯，但是你还是很难做出判断，实际上我们人在识别一个图像的时候，往往会不由自主的提取，比如存货、颜色、花纹这样的元素，也就是说图像作为一个二维的物体，**在二维平面相邻像素之间是存在关联的，我们强行把它降到一维，也就破坏了这些关联，失去了它重要的特征**。​

再举个例子，下面这些都是我瞎编的，你从来没有见过的两类东西，这些我称之为咕叽咕叽，这些我称之为呱啦呱，啦那么请问这个是咕叽咕叽还是呱啦呱啦呢？相信你很容易就能判别出来，所以一旦我们能够提取出这些特征，那就很容易作出判断。也就是说这些特征对提高模型的泛化能力有很大的作用。

![image](https://cdn.jsdelivr.net/gh/Achuan-2/PicBed@pic/assets/image-20220815170616-8zugrhu.png)​

基于这种想法，人们把卷积运算引入到了神经网络，卷积运算的过程是这样的，这是一张28×28的灰度图，当然28×28还是有点大，我不好做图你看着也乱，所以我们用一个8×8的灰度图举例，我们知道对于灰度图这些像素点也就是0~255之间的不同数字，所以我们可以把它看作是一个8×8的矩阵，或者用计算机的话来说就是一个二维的数组，然后我们手动构建一个3×3的小矩阵，然后从左上角开始把这个小的照在这个大的上面，把对应的元素相乘，结果再加到一起得到一个新的值，完成以后把这个小的向右挪一个同样和大的对应的元素相乘，结果相加又得到一个值，再左右挪动，重复这个过程，直到顶到头。​我们再回到最左边向下挪动一个，从左到右再来一遍。顶到头后我们再回到最左边，并继续向下挪动一个，按照这个模式直到顶到最下方最右方为止，这就是图像的卷积操作。

![image](https://cdn.jsdelivr.net/gh/Achuan-2/PicBed@pic/assets/image-20220815170704-zksxyqv.png)​

而右边这些每次得到的新值按照位置排列后得到一个6×6的新图片，当然一个像素的灰度值是一个自己的最大值255，所以如果我们想要把这个卷积的结果显示成图片的话，需要把超过255的像素点都处理成255，这就是这个8×8的原始灰度图卷积之后的样子。而这个3×3的小矩阵也就是卷机盒有时候也被称之为过滤器，当然我个人更喜欢叫卷机盒，因为听起来似乎格调高一点，所以为什么这种卷积运算就可以提取出图像，诸如轮廓花纹颜色的特征。

![image](https://cdn.jsdelivr.net/gh/Achuan-2/PicBed@pic/assets/image-20220815170716-z0lbdii.png)​

我们可以用一个比较好理解的卷积和来简单的说明这个问题。我们的图像是这样的，大家想一下用这个卷集合卷完之后会是什么样的效果呢？没错，把垂直的边缘给提取出来的。

![image](https://cdn.jsdelivr.net/gh/Achuan-2/PicBed@pic/assets/image-20220815170731-uloenj9.png)​

这个卷积合的作用实际上是用来做垂直边缘的提取，这个大图比较麻烦，我们用两张8×8的小图来看一下细节，这是他们用这个卷积和卷积的结果，你会发现结果图片都开始显现，垂直条纹的特征。

![image](https://cdn.jsdelivr.net/gh/Achuan-2/PicBed@pic/assets/image-20220815170804-9nimrp4.png)​

为了让事情更加简单，我们再搞一张极端情况的图片，这张小图中间部分很明显是图像的一个垂直边界，比如一个杯子的边缘部分，那么在卷积的时候你会发现因为这个图像左侧的像素灰度值都是60，而卷积荷的左侧一列是1，右侧一列是-1，中间一列是0，元素相乘再相加后就变成了0，所以这个图像左侧部分卷出来的结果都是0，很黑，而在右边像素灰度值都是零卷出来的，结果也都是0也很黑，只有在中间部分，比如这里这三个60×1相加得到180，中间的结果是0，右边的结果也是0，所以结果就是180，这一列下来都是180，还有右边这一列结果也都是180，如果我们把卷积的结果画出来，那么就是这样一个明亮的垂直边界，实际上如果我们仔细的观察这个卷集合，你就会发现因为它们在垂直方向上左右对称的两列值都是相反数，所以遇到图像中灰度值相近的3×3的像素块，它们就会在左右1正1负之间相互抵消，最后的结果变为0，也就是说很黑，而对于像中间部分左侧大右侧小的3×3的像素块，这是典型的垂直边缘特征。

![image](https://cdn.jsdelivr.net/gh/Achuan-2/PicBed@pic/assets/image-20220815170830-bidldvz.png)​

你会发现这种左大右小的不对称导致抵消作用降低，而像这种右侧全是命的情况，右侧的赋值完全没有抵消左侧正直的作用。不仅如此，因为卷积和左侧一列是三个，一加起来之后，结果把这个值变得很大，换句话说，边缘的特征被凸显了出来，同样的道理，我们还可以用这样的一个卷集合做出水平提取的效果，你可以使用这样只有横线和竖线的图片去测试，结果将非常的明显，垂直检测的卷集合把水平线弄没了，而水平检测的卷积和把垂直线弄没了。

![image](https://cdn.jsdelivr.net/gh/Achuan-2/PicBed@pic/assets/image-20220815170900-j7pnz25.png)​

实际上卷积是一种在图像处理领域非常常见的操作，现在很多图像处理软件中都会利用到卷积运算给图片加上效果。

![image](https://cdn.jsdelivr.net/gh/Achuan-2/PicBed@pic/assets/image-20220815170916-t8k1ebs.png)​

那我们再通过一个简单的例子看，看一下卷积是怎样在手写体识别问题上发挥作用的，这是手写题1，我们把它往后挪一点，这还是1只不过写的稍稍靠右了一点，我们在这个一上画一个小小的横，这是数字7，那么对于一个普通的全连接深度神经网络而言，第二个1和第一个一更接近还是这个7更接近，很明显是7，虽然作为人我们知道第二个一确实也是一，但当我们把图片变成一个数组之后，因为7的余数和第二个一一模一样，所以你会发现这个一在数组中有很多对应特征位置的值和这个7一样，因为它相对于第一个向后挪动了一点点，反倒和第一个一对应位置的特征值相趋甚远。

![image](https://cdn.jsdelivr.net/gh/Achuan-2/PicBed@pic/assets/image-20220815170940-zlulox5.png)​

但如果我用这样的一个卷积和，对这两个1和这个7进行卷积便得到这样的结果，很明显这个卷积和提取的是横向的边界，所以此刻到底谁更像谁就发生了令人愉快的改变

![image](https://cdn.jsdelivr.net/gh/Achuan-2/PicBed@pic/assets/image-20220815170945-i97r3c6.png)​

## 编程实验

好的，同学们，我们开始做本节课的编程实验，那本次编程实验呢我们就用凯瑞斯搭建一个深度神经网络，来尝试一下经典的mnist的数据集，那关于卷积神经网络的使用，我们在下一节课完整的讲述卷积神经网络的细节之后再来实现。

* 加载数据集：mnist数据集，为手写数字的图片数据集，训练数据60000张，测试数据10000张，每张图片是28*28像素的黑白图片

  ```python
  from keras.datasets import mnist
  (X_train, Y_train), (X_test, Y_test) = mnist.load_data()
  ```
* 数据预处理

  * 图像数据抽平到一阶张量，比如mnist数据集是28*28像素的黑白图片，就抽平为$28 \times 28=784$ 维向量。

    ```python
    X_train = X_train.reshape(X_train.shape[0], -1)
    X_test = X_test.reshape(X_test.shape[0], -1)
    ```
  * 为了方便梯度下降收敛，需要把像素点的大小归一化到0-1之间

    ```python
    X_train = X_train/255
    X_test = X_test/255
    ```
  * 对Y标签进行独热编码，这是为了输出层可以多分类。数据集是0-9的数字手写，所以就是10维向量来存储类别，0用[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]表示，2用[0, 0, 1, 0, 0, 0, 0, 0, 0, 0] 表示。这样输出层也输出10个值，第几个神经元的输出值最大，就可以认为是哪一类了`np.argmax(Y_test_pre[i])`。

    ```python
    Y_train = to_categorical(Y_train, 10)
    Y_test = to_categorical(Y_test, 10)
    ```
* 网络构建

  * 网络拓扑图

    ![mnist](https://cdn.jsdelivr.net/gh/Achuan-2/PicBed@pic/assets/mnist-20220812202236-b8h89lv.jpg)​
  * 三层隐藏层，每层256个神经元，激活函数选择ReLU函数；  
    输出层选择Softmax，使得输出的十个值总和为1。

    ```python
    model = Sequential()
    model.add(Dense(units=256, activation='relu', input_dim=784))
    model.add(Dense(units=256, activation='relu'))
    model.add(Dense(units=256, activation='relu')) 
    model.add(Dense(units=10, activation='softmax'))  # 输出层用softmax函数
    model.compile(loss='categorical_crossentropy', optimizer=SGD(
        learning_rate=0.05), metrics=['accuracy'])  # 多分类问题使用交叉熵做代价函数
    ```
* 全部代码

  ```python
  from keras.utils import to_categorical
  import numpy as np
  import matplotlib.pyplot as plt
  from keras.models import Sequential
  from keras.layers import Dense
  from keras.optimizers import SGD
  from keras.models import load_model
  from keras.datasets import mnist

  (X_train, Y_train), (X_test, Y_test) = mnist.load_data()


  X_train = X_train.reshape(X_train.shape[0], -1)/255
  X_test = X_test.reshape(X_test.shape[0], -1)/255

  Y_train = to_categorical(Y_train, 10)
  Y_test = to_categorical(Y_test, 10)


  # 创建模型
  model = Sequential()
  model.add(Dense(units=256, activation='relu', input_dim=784))
  model.add(Dense(units=256, activation='relu'))
  model.add(Dense(units=256, activation='relu')) 
  model.add(Dense(units=10, activation='softmax'))  # 输出层用softmax函数
  model.compile(loss='categorical_crossentropy', optimizer=SGD(
      learning_rate=0.05), metrics=['accuracy'])  # 多分类问题使用交叉熵做代价函数
  # 开始训练
  model.fit(X_train, Y_train, epochs=5000, batch_size=2000, verbose=1)


  # 训练完毕，查看loss和accuracy
  loss, accuracy = model.evaluate(X_test, Y_test)
  print(f"{loss=}")
  print(f"{accuracy=}")
  # 保存模型
  model.save('./model/10_model.h5')
  ```
* 识别效果：训练集达到了100%正确率，测试集则只有97.82%

​
